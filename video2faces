#!/opt/virtualenv/computer_vision/bin/python3


# 20220502
# https://tsurugi-linux.org
#
# by Visi@n
# LICENSE:
# THIS SCRIPT USE FACE_RECOGNITION LIBRARY [https://github.com/ageitgey/face_recognition/blob/master/LICENSE]
# THIS SCRIPT HAS BEEN MODIFIED BY Antonio 'Visi@n' Broi [antonio@tsurugi-linux.org] and it's licensed under the MIT License

# Example: video2faces.py -i video.mp4 -o ~/02.computer_vision/03.reports

import face_recognition
import cv2
import time
from PIL import Image
from datetime import datetime
import argparse
import os

ap = argparse.ArgumentParser()
ap.add_argument("-i", "--input", default=0,
	help="input from video files or webcam (if no input is specified)")
ap.add_argument("-o", "--output", required=True,
	help="output directory")
args = vars(ap.parse_args())

video_capture = cv2.VideoCapture(args["input"])


# Initialize some variables
face_locations = []
process_this_frame = True

while True:
    # Grab a single video frame
	ret, frame = video_capture.read()


	face_locations = face_recognition.face_locations(frame, number_of_times_to_upsample=0, model="cnn")

	print("I found {} face(s) in this picture".format(len(face_locations)))

	for face_location in face_locations:

		# Print the location of each face in the current image
		top, right, bottom, left = face_location
		print("A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}".format(top, left, bottom, right))

		# You can access the actual face itself like this:
		face_image = frame[top:bottom, left:right]
		pil_image = Image.fromarray(face_image)
		#pil_image.show()
		filename = datetime.now().strftime("%Y_%m_%d_%H_%M_%S") +'.png'
		if not os.path.isdir(args["output"]): os.mkdir(args["output"])
		
		pil_image.convert('RGB').save(args["output"]+'/'+filename)
		cv2.imshow("faces", frame)


	# Hit 'q' on the keyboard to quit!
	if cv2.waitKey(1) & 0xFF == ord('q'):
		break

# Release handle from webcam
video_capture.release()
cv2.destroyAllWindows()
